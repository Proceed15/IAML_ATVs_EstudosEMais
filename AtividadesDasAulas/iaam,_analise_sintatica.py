# -*- coding: utf-8 -*-
"""IAAM, Analise_Sintatica.ipynb

Automatically generated by Colab.

Original file is located at Google Colab

# O que √© An√°lise Sint√°tica?

A An√°lise Sint√°tica (ou parsing) consiste em identificar a estrutura gramatical de uma frase, ou seja, entender como as palavras se organizam e se relacionam. Em chatbots, isso √© essencial para interpretar corretamente as inten√ß√µes do usu√°rio e extrair entidades importantes.

Por exemplo, na frase:

> "Quero reservar um hotel em S√£o Paulo para amanh√£"

A an√°lise sint√°tica ajuda o chatbot a identificar:

- Verbo principal: "reservar"
- Objeto direto: "um hotel"
- Complemento de lugar: "em S√£o Paulo"
- Complemento de tempo: "para amanh√£"

## Por que √© importante em chatbots?
- Identificar inten√ß√£o (ex: reservar, perguntar, cancelar)
- Extrair entidades (ex: datas, locais, nomes)
- Compreender contexto gramatical para evitar confus√µes
"""

!pip install -U spacy
!python -m spacy download pt_core_news_sm

import spacy

# Carregando o modelo de portugu√™s
nlp = spacy.load("pt_core_news_sm")

# Frase simulando entrada do usu√°rio no chatbot
frase = "Gostaria de agendar uma consulta com o doutor Jo√£o amanh√£ √†s 15 horas."

# Processar a frase
doc = nlp(frase)

# Exibir an√°lise sint√°tica
print(f"{'Token':<15}{'Posi√ß√£o':<10}{'Tipo':<10}{'Depend√™ncia':<15}{'Palavra Pai':<15}")
print("="*70)
for token in doc:
    print(f"{token.text:<15}{token.i:<10}{token.pos_:<10}{token.dep_:<15}{token.head.text:<15}")

"""| POS tag (`token.pos_`) | Descri√ß√£o                        | Exemplo em ingl√™s           |
|------------------------|----------------------------------|-----------------------------|
| `ADJ`                  | Adjetivo                         | *happy, large, round*       |
| `ADP`                  | Preposi√ß√£o ou p√≥sposi√ß√£o         | *in, on, under*             |
| `ADV`                  | Adv√©rbio                         | *quickly, never, very*      |
| `AUX`                  | Verbo auxiliar                   | *is, have, do*              |
| `CONJ`                 | Conjun√ß√£o                        | *and, but* (pouco usado)    |
| `CCONJ`                | Conjun√ß√£o coordenativa           | *and, or, but*              |
| `SCONJ`                | Conjun√ß√£o subordinativa          | *because, if, when*         |
| `DET`                  | Determinante                     | *the, a, an, some*          |
| `INTJ`                 | Interjei√ß√£o                      | *wow, oops, hello*          |
| `NOUN`                 | Substantivo comum                | *dog, car, computer*        |
| `PROPN`                | Substantivo pr√≥prio              | *Alice, London, Google*     |
| `NUM`                  | N√∫mero                           | *one, 2, third*             |
| `PART`                 | Part√≠cula (ex: ‚Äúto‚Äù de infinitivo)| *to, 's, not*               |
| `PRON`                 | Pronome                          | *he, she, it, they*         |
| `PUNCT`                | Pontua√ß√£o                        | *., !, ?*                   |
| `SYM`                  | S√≠mbolo                          | *$, %, ¬©*                   |
| `VERB`                 | Verbo principal                  | *run, eat, think*           |
| `X`                    | Outro / desconhecido             | caracteres estranhos        |
| `SPACE`                | Espa√ßo em branco                 |                             |

## 1. **Identificar a Inten√ß√£o Baseada no Verbo Raiz (`ROOT`)**

### Conceito:
O verbo principal da frase normalmente est√° ligado √† a√ß√£o que o usu√°rio quer realizar. Em `spaCy`, ele aparece como o **token com depend√™ncia `ROOT`**.

### Exemplo:
Frase:  
> **"Gostaria de agendar uma consulta com o doutor Jo√£o amanh√£ √†s 15 horas."**

Verbo raiz:
```python
for token in doc:
    if token.dep_ == "ROOT":
        print(f"Verbo principal (inten√ß√£o): {token.text}")
```

üí¨ Sa√≠da:
```
Verbo principal (inten√ß√£o): Gostaria
```

> **Regra**: Se o verbo raiz for ‚Äúgostaria‚Äù, ‚Äúquero‚Äù, ‚Äúpreciso‚Äù, ‚Äúmarcar‚Äù ‚Üí inten√ß√£o prov√°vel √© **agendar**.

## 2. **Identificar Nomes Pr√≥prios (ex: "Jo√£o")**

### Conceito:
Nomes pr√≥prios s√£o classificados como `PROPN` (Proper Noun). S√£o √∫teis para descobrir **com quem** a a√ß√£o est√° sendo realizada (ex: m√©dico, professor, cliente).

### Exemplo:
```python
nomes = [token.text for token in doc if token.pos_ == "PROPN"]
print("Nomes pr√≥prios detectados:", nomes)
```

Sa√≠da:
```
Nomes pr√≥prios detectados: ['Jo√£o']
```

> **Regra**: Combine com o substantivo anterior (‚Äúdoutor‚Äù, ‚Äúprofessor‚Äù, etc.) para criar uma entidade: **‚Äúdoutor Jo√£o‚Äù**.

## 3. **Extrair Datas e Hor√°rios**

### Conceito:
Datas e hor√°rios podem ser:
- Adv√©rbios de tempo: `amanh√£`, `hoje`, `depois`
- N√∫meros com substantivos como "horas": `15 horas`
- Preposi√ß√µes: `√†s 15 horas`, `em 10 de abril`, etc.

### Exemplo:
```python
datas = []
horarios = []

for i, token in enumerate(doc):
    # Data por adv√©rbio
    if token.text.lower() in ["hoje", "amanh√£", "depois"]:
        datas.append(token.text)

    # Hor√°rio com n√∫mero + "horas"
    if token.like_num and i+1 < len(doc) and doc[i+1].text.lower() == "horas":
        horarios.append(f"{token.text} {doc[i+1].text}")

print("Datas detectadas:", datas)
print("Hor√°rios detectados:", horarios)
```

Sa√≠da:
```
Datas detectadas: ['amanh√£']
Hor√°rios detectados: ['15 horas']
```

> **Regra**: Agrupar essas informa√ß√µes como parte dos **slots** da inten√ß√£o.

## Exemplo
"""

import spacy

nlp = spacy.load("pt_core_news_sm")
frase = "Gostaria de agendar uma consulta com o doutor Jo√£o amanh√£ √†s 24 horas."
doc = nlp(frase)

intencao = ""
nome = ""
data = ""
hora = ""

# 1. Inten√ß√£o
for token in doc:
    if token.dep_ == "ROOT":
        intencao = token.text.lower()

# 2. Nome pr√≥prio
nomes_proprios = [token.text for token in doc if token.pos_ == "PROPN"]

# 3. Data e Hora
for i, token in enumerate(doc):
    if token.text.lower() in ["hoje", "amanh√£", "depois"]:
        data = token.text
    if token.like_num and i+1 < len(doc) and doc[i+1].text.lower() == "horas":
        hora = f"{token.text} {doc[i+1].text}"

# 4. Nome completo (ex: "doutor Jo√£o")
for i in range(len(doc)-1):
    if doc[i].text.lower() in ["doutor", "professor", "sr."] and doc[i+1].pos_ == "PROPN":
        nome = f"{doc[i].text} {doc[i+1].text}"

# Resultado final
print("Interpreta√ß√£o da frase:")
print(f"‚û° Inten√ß√£o: {intencao}")
print(f"‚û° Pessoa: {nome or nomes_proprios[0]}")
print(f"‚û° Data: {data}")
print(f"‚û° Hora: {hora}")

"""# Exemplo 2"""

# Instala√ß√£o de depend√™ncias
# !pip install -q spacy
# !python -m spacy download pt_core_news_sm

# Fun√ß√£o de interpreta√ß√£o sint√°tica
import spacy

# Carrega modelo de portugu√™s
nlp = spacy.load("pt_core_news_sm")

def interpretar_frase(frase: str):
    doc = nlp(frase)

    intencao = ""
    nome = ""
    data = ""
    hora = ""

    # 1. Inten√ß√£o com base no verbo ROOT
    for token in doc:
        if token.dep_ == "ROOT":
            intencao = token.lemma_.lower()  # verbo raiz lematizado

    # 2. Nome pr√≥prio
    nomes_proprios = [token.text for token in doc if token.pos_ == "PROPN"]

    for i in range(len(doc)-1):
        if doc[i].text.lower() in ["doutor", "professor", "sr.", "sra."] and doc[i+1].pos_ == "PROPN":
            nome = f"{doc[i].text} {doc[i+1].text}"
            break

    if not nome and nomes_proprios:
        nome = nomes_proprios[0]

    # 3. Data e hora
    for i, token in enumerate(doc):
        if token.text.lower() in ["hoje", "amanh√£", "depois"]:
            data = token.text

        if token.like_num and i+1 < len(doc) and doc[i+1].text.lower() == "horas":
            hora = f"{token.text} {doc[i+1].text}"

    # 4. Inten√ß√µes mapeadas
    mapa_intencoes = {
        "agendar": "agendar_consulta",
        "marcar": "agendar_consulta",
        "cancelar": "cancelar_consulta",
        "remarcar": "remarcar_consulta",
        "gostar": "agendar_consulta",
        "querer": "agendar_consulta",
        "precisar": "agendar_consulta"
    }
    intencao_final = mapa_intencoes.get(intencao, "indefinida")

    return {
        "entrada": frase,
        "intencao": intencao_final,
        "slots": {
            "pessoa": nome,
            "data": data,
            "hora": hora
        },
        "tokens": doc
    }

# Exemplos de teste
entradas = [
    "Gostaria de agendar uma consulta com o doutor Jo√£o amanh√£ √†s 15 horas.",
    "Preciso remarcar com a professora Ana hoje √†s 10 horas.",
    "Quero cancelar minha consulta com o Jo√£o.",
    "Agendar reuni√£o com o professor Pedro amanh√£.",
    "Gostaria de marcar um hor√°rio com a doutora Camila √†s 9 horas."
]

for frase in entradas:
    resultado = interpretar_frase(frase)
    print("="*70)
    print("Entrada:", resultado["entrada"])
    print("Inten√ß√£o:", resultado["intencao"])
    print("Slots:", resultado["slots"])
    print(f"{'Token':<15}{'Posi√ß√£o':<10}{'Tipo':<10}{'Depend√™ncia':<15}{'Palavra Pai':<15}")
    print("="*70)
    for token in resultado["tokens"]:
        print(f"{token.text:<15}{token.i:<10}{token.pos_:<10}{token.dep_:<15}{token.head.text:<15}")
    print("\n\n")