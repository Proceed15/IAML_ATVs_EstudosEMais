# -*- coding: utf-8 -*-
"""Aula 4, Exemplo PNL.ipynb

Automatically generated by Colab.

Original file is located at Google Colab
"""

!pip cache purge

!pip uninstall -y gensim numpy
!pip uninstall -y tsfresh thinc
!pip install --upgrade gensim numpy scipy

# Bibliotecas
import numpy as np
import nltk

from nltk.tokenize import word_tokenize
#from gensim.models import Word2Vec
from sklearn.decomposition import PCA
from sklearn.metrics.pairwise import cosine_similarity
from sklearn.feature_extraction.text import CountVectorizer
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.feature_selection import chi2

nltk.download('punkt')
nltk.download('punkt_tab')
nltk.download('stopwords')

# chatbot perguntas frequentes

faq = {
    "horário de funcionamento": "Nosso atendimento é das 09 às 18h, de segunda à sexta.",
    "formas de pagamento": "Aceitamos cartão de débito, crédito e pix.",
    "tempo de entrega": "O prazo de entrega varia de 3 a 7 dias úteis.",
    "tempo de funcionamento": "Nosso atendimento é de segunda à sexta."
}

# preprocessamento
stopwords = set(nltk.corpus.stopwords.words('portuguese'))

def preprocess(text):
  words = nltk.word_tokenize(text.lower())
  return " ".join([word for word in words if word.isalnum() and word not in stopwords])

# TF-IDF
vectorizer = TfidfVectorizer()
X = vectorizer.fit_transform([preprocess(q) for q in faq.keys()])
X.toarray();
print(X);



def chatbot(question):
  question_proc = preprocess(question)
  print(question_proc)
  question_vect = vectorizer.transform([question_proc])
  print(question_vect)
  scores = cosine_similarity(question_vect, X)
  best_match = scores.argmax()

  return list(faq.values())[best_match]

print(chatbot("Qual a formas de pagamento"))

from sklearn.feature_extraction.text import TfidfVectorizer

#Precisa ser uma Matriz de Objetos
corpus = ["O rato roeu a roupa do rei de Roma"]

# Criando o modelo TF-IDF
vectorizer = TfidfVectorizer()
X_tfidf = vectorizer.fit_transform(corpus)

# Convertendo para array e exibindo a matriz TF-IDF
print("Vocabulário:", vectorizer.get_feature_names_out())
# print("Matriz TF-IDF:\n", X_tfidf.toarray())

matriz_formatada = [[f"{valor:.3f}" for valor in linha] for linha in X_tfidf.toarray()]
for linha in matriz_formatada:
    print(linha)

# Análise de Sentimentos

frases = ["Estou muito Feliz!", #Positivo
          "O Atendimento foi horrível e demorado!", #Negativo
          "Gostei muito da experiência, voltarei!", #Positivo
          "Eu adorei o filme, foi incrível!", #Positivo
          "Ótima Experiência!", #Positivo
          "Eu fiz o Filme e Gostei Muito!", #Positivo
          "Foi bom e precisa Melhorar", #Positivo
          "Precisa Melhorar", #Negativo
          "Está Muito Melhor", #Positivo
          ]

labels = [1, 0, 1, 1, 1, 1, 1, 0, 1]

#bag of Words
vectorizer = CountVectorizer()
X = vectorizer.fit_transform(frases)

chi2_scores, _ = chi2(X, labels)
selected_words = np.array(vectorizer.get_feature_names_out())[np.argsort(chi2_scores)[-5:]]
selected_words

def analisar_sentimento(texto):
  tokens = texto.lower().split()
  score = sum(1 for word in tokens if word in selected_words)
  print(score)

  return "Positivo" if score >= 1 else "Negativo"

print(analisar_sentimento("Gostei Muito"))
#print(analisar_sentimento("Gostei da aula")) #Dá Negati

